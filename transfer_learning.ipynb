{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a851fb-eeec-40c9-9523-ec6a7a596ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10401303-741d-4037-8e0a-b1d19bb1dd5b",
   "metadata": {},
   "source": [
    "#### 1- Define Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5439bb2-8489-4141-b72d-6c3e8b3eaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Mean and std for ImageNet\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f4a6c-05d3-4e56-a6f5-1a4514452a67",
   "metadata": {},
   "source": [
    "#### 2- Download and load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a1f53b-1a6b-4287-a61d-4989ecfde924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369kKB [00:12, 28.6kKB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to download a file from a URL\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length', 0))\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in tqdm(r.iter_content(chunk_size=chunk_size), total=total_size//chunk_size, unit='KB', unit_scale=True):\n",
    "            fd.write(chunk)\n",
    "\n",
    "# URL and path for the Hymenoptera dataset\n",
    "url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "data_dir = 'data'\n",
    "zip_path = os.path.join(data_dir, 'hymenoptera_data.zip')\n",
    "\n",
    "# Create directory if it does not exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "download_url(url, zip_path)\n",
    "\n",
    "# Extract the dataset\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)\n",
    "\n",
    "print(\"Dataset downloaded and extracted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f622f0-8f62-4f0f-8cdc-a9719df1c14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 244, 'val': 153}\n",
      "['ants', 'bees']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "data_dir = 'data/hymenoptera_data'  # Example dataset directory\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(dataset_sizes)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f55e7-0323-4419-8575-a329f5b2b070",
   "metadata": {},
   "source": [
    "#### 3- Load a Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45258253-0feb-4b62-a67d-89d9b2f65d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final layer\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device) # stands for model fine-tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28edc7-3b9a-4cbc-a49f-8163f7b2ee0d",
   "metadata": {},
   "source": [
    "#### 4- Define the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8c7cd5-0d4a-4ef8-9af3-eab937354e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e8db2-de50-4267-9f00-8c2a19c6df39",
   "metadata": {},
   "source": [
    "#### 5- Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc70ca34-d02c-4b61-94af-f904c22fedcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6188 Acc: 0.7705\n",
      "val Loss: 81.4885 Acc: 0.5425\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5858 Acc: 0.7828\n",
      "val Loss: 34.3561 Acc: 0.5490\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5317 Acc: 0.7500\n",
      "val Loss: 2.3087 Acc: 0.6601\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4562 Acc: 0.8074\n",
      "val Loss: 8.9824 Acc: 0.5752\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3977 Acc: 0.8115\n",
      "val Loss: 0.5048 Acc: 0.7712\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3071 Acc: 0.8443\n",
      "val Loss: 0.5140 Acc: 0.8431\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2916 Acc: 0.8934\n",
      "val Loss: 0.4730 Acc: 0.8758\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2585 Acc: 0.8689\n",
      "val Loss: 0.3885 Acc: 0.8954\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2444 Acc: 0.8934\n",
      "val Loss: 0.3156 Acc: 0.8824\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 0.9303\n",
      "val Loss: 0.2907 Acc: 0.9085\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2135 Acc: 0.9098\n",
      "val Loss: 0.2642 Acc: 0.9085\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9098\n",
      "val Loss: 0.2604 Acc: 0.9150\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1674 Acc: 0.9303\n",
      "val Loss: 0.2736 Acc: 0.9085\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9426\n",
      "val Loss: 0.3110 Acc: 0.8758\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1368 Acc: 0.9467\n",
      "val Loss: 0.2799 Acc: 0.8824\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9344\n",
      "val Loss: 0.2799 Acc: 0.8889\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1606 Acc: 0.9303\n",
      "val Loss: 0.2704 Acc: 0.9085\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1547 Acc: 0.9426\n",
      "val Loss: 0.2731 Acc: 0.9085\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1215 Acc: 0.9631\n",
      "val Loss: 0.2694 Acc: 0.9085\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9385\n",
      "val Loss: 0.2700 Acc: 0.9085\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9467\n",
      "val Loss: 0.2659 Acc: 0.9085\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1284 Acc: 0.9549\n",
      "val Loss: 0.2677 Acc: 0.9150\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9426\n",
      "val Loss: 0.2672 Acc: 0.9085\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9631\n",
      "val Loss: 0.2648 Acc: 0.9085\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9385\n",
      "val Loss: 0.2664 Acc: 0.9150\n",
      "\n",
      "Training complete in 10m 11s\n",
      "Best val Acc: 0.9150\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())     # save the best model weights\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # Enables gradient computation only during training.\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854801e-d1e0-494c-87dc-0e13b11df284",
   "metadata": {},
   "source": [
    "#### 6- Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ebacc95-45e1-452d-8dc5-9085f0dbe8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 91.50%\n"
     ]
    }
   ],
   "source": [
    "model_ft.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the validation images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef51ebd-3320-4a54-85d0-636270d683a8",
   "metadata": {},
   "source": [
    "# Saving and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ebc83-45e9-4e13-951c-ba60931f2113",
   "metadata": {},
   "source": [
    "#### 1- Saving and Loading the Entire Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440815ef-4211-418a-aed4-c08dc2d81684",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'model_ft.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf51c206-21a5-4ac3-a500-7c16b60eed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_ft.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e5a6c-fab9-43f4-807a-5f6179919c1d",
   "metadata": {},
   "source": [
    "#### 2- Saving and Loading Only the Model State Dict (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78df209b-5547-4a46-acd6-ae2abc3e4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'model_ft_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "372550b8-1514-4c4e-ae59-f0e5d94c5385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final layer\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device) # stands for model fine-tuned\n",
    "\n",
    "model_ft.load_state_dict(torch.load('model_ft_state_dict.pth'))\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b2e35-e10d-4869-a34a-052d4134c0b7",
   "metadata": {},
   "source": [
    "#### 3- Saving and Loading the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa0e57-f5ac-492e-ba3c-f88fdb0da740",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eec66d-6e92-4c1f-be49-917ff88c09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelClass()\n",
    "optimizer = OptimizerClass(model.parameters())\n",
    "\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
